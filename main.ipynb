{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "995d07be",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2024-04-30T12:35:08.829130Z",
     "iopub.status.busy": "2024-04-30T12:35:08.828674Z",
     "iopub.status.idle": "2024-04-30T12:35:16.485835Z",
     "shell.execute_reply": "2024-04-30T12:35:16.484485Z"
    },
    "papermill": {
     "duration": 7.669224,
     "end_time": "2024-04-30T12:35:16.489101",
     "exception": false,
     "start_time": "2024-04-30T12:35:08.819877",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Imports\n",
    "import os\n",
    "import sys\n",
    "import glob\n",
    "import torch\n",
    "\n",
    "import torchvision\n",
    "from tqdm import trange\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import datetime as dt\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import matplotlib.pyplot   as plt\n",
    "import albumentations as A\n",
    "from albumentations.pytorch.transforms import ToTensorV2\n",
    "import time\n",
    "from datetime import datetime\n",
    "\n",
    "from PIL import Image\n",
    "from torch.utils.data  import Dataset\n",
    "from torch.autograd    import Variable\n",
    "from torch.optim       import lr_scheduler\n",
    "\n",
    "from torch.utils.data  import Dataset, DataLoader\n",
    "from torch.utils.data.sampler import SubsetRandomSampler\n",
    "from torchvision       import transforms, datasets, models\n",
    "from os                import listdir, makedirs, getcwd, remove\n",
    "from os.path           import isfile, join, abspath, exists, isdir, expanduser\n",
    "from efficientnet_pytorch import EfficientNet\n",
    "\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "5db195b0",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-30T12:35:16.505264Z",
     "iopub.status.busy": "2024-04-30T12:35:16.503830Z",
     "iopub.status.idle": "2024-04-30T12:35:16.511044Z",
     "shell.execute_reply": "2024-04-30T12:35:16.509676Z"
    },
    "papermill": {
     "duration": 0.01805,
     "end_time": "2024-04-30T12:35:16.513827",
     "exception": false,
     "start_time": "2024-04-30T12:35:16.495777",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "origin_path = \"./dataset\"\n",
    "train_path = join(origin_path, \"train/train\")\n",
    "test_path = join(origin_path,\"test/test\")\n",
    "extraimage_path = join(origin_path, \"extraimages/extraimages\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "0c47a78c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-30T12:35:16.529346Z",
     "iopub.status.busy": "2024-04-30T12:35:16.528835Z",
     "iopub.status.idle": "2024-04-30T12:35:16.538012Z",
     "shell.execute_reply": "2024-04-30T12:35:16.536597Z"
    },
    "papermill": {
     "duration": 0.020271,
     "end_time": "2024-04-30T12:35:16.540690",
     "exception": false,
     "start_time": "2024-04-30T12:35:16.520419",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.11/site-packages/albumentations/augmentations/dropout/cutout.py:49: FutureWarning: Cutout has been deprecated. Please use CoarseDropout\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# Transformations for both the training and testing data\n",
    "mean=[0.485, 0.456, 0.406]\n",
    "std=[0.229, 0.224, 0.225]\n",
    "\n",
    "# Do data transforms here, Try many others\n",
    "train_transforms = A.Compose(\n",
    "        [\n",
    "            A.HorizontalFlip(p=0.5),\n",
    "            A.VerticalFlip(p=0.5),\n",
    "            A.Rotate(),\n",
    "            A.Resize(height=256, width=256, p=1),\n",
    "            A.Cutout(num_holes=8, max_h_size=32, max_w_size=32, fill_value=0, p=0.5),\n",
    "             A.ToFloat(max_value=255.0),\n",
    "            ToTensorV2(p=1.0),\n",
    "        ]\n",
    "    )\n",
    "\n",
    "test_transforms = A.Compose(\n",
    "        [\n",
    "            A.Resize(height=256, width=256, p=1),\n",
    "             A.ToFloat(max_value=255.0),\n",
    "            ToTensorV2(p=1.0),\n",
    "        ]\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "06829670",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-30T12:35:16.555768Z",
     "iopub.status.busy": "2024-04-30T12:35:16.555248Z",
     "iopub.status.idle": "2024-04-30T12:35:16.567146Z",
     "shell.execute_reply": "2024-04-30T12:35:16.566217Z"
    },
    "papermill": {
     "duration": 0.022529,
     "end_time": "2024-04-30T12:35:16.569691",
     "exception": false,
     "start_time": "2024-04-30T12:35:16.547162",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class CassavaDataset(Dataset):\n",
    "    def __init__(self, path, transform=None):\n",
    "        self.classes = os.listdir(path)\n",
    "        self.path = [f\"{path}/{className}\" for className in self.classes]\n",
    "        self.file_list = [glob.glob(f\"{x}/*\") for x in self.path]\n",
    "        self.transform = transform\n",
    "        self.classes_dict = {}\n",
    "\n",
    "        files = []\n",
    "        for i, className in enumerate(self.classes):\n",
    "            for fileName in self.file_list[i]:\n",
    "                self.classes_dict[i] = className\n",
    "                files.append([i, className, fileName])\n",
    "        self.file_list = files\n",
    "        files = None\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.file_list)\n",
    "    \n",
    "    def get_image_filename(self, idx):\n",
    "        file_path = self.file_list[idx][2]\n",
    "        file_name = file_path.split(\"/\")[-1]\n",
    "        return file_name\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        fileName = self.file_list[idx][2]\n",
    "        classCategory = self.file_list[idx][0]\n",
    "        im = Image.open(fileName)\n",
    "        if self.transform:\n",
    "            im = self.transform(image= np.asarray(im))[\"image\"]\n",
    "            \n",
    "        return im, classCategory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "a755ef0e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-30T12:35:16.586009Z",
     "iopub.status.busy": "2024-04-30T12:35:16.584612Z",
     "iopub.status.idle": "2024-04-30T12:35:17.035713Z",
     "shell.execute_reply": "2024-04-30T12:35:17.033499Z"
    },
    "papermill": {
     "duration": 0.461985,
     "end_time": "2024-04-30T12:35:17.038476",
     "exception": true,
     "start_time": "2024-04-30T12:35:16.576491",
     "status": "failed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_data = CassavaDataset(train_path, transform=train_transforms)\n",
    "test_data = CassavaDataset(test_path, transform=test_transforms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "650200d7",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-03-29T11:50:49.291431Z",
     "iopub.status.busy": "2021-03-29T11:50:49.290391Z",
     "iopub.status.idle": "2021-03-29T11:50:49.293477Z",
     "shell.execute_reply": "2021-03-29T11:50:49.292843Z"
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "validation_split = .2\n",
    "shuffle_dataset = True\n",
    "random_seed= 42\n",
    "\n",
    "# Creating data indices for training and validation splits:\n",
    "dataset_size = len(train_data)\n",
    "indices = list(range(dataset_size))\n",
    "split = int(np.floor(validation_split * dataset_size))\n",
    "\n",
    "if shuffle_dataset :\n",
    "    np.random.seed(random_seed)\n",
    "    np.random.shuffle(indices)\n",
    "\n",
    "train_indices, val_indices = indices[split:], indices[:split]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "84509656",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-03-29T11:50:49.323640Z",
     "iopub.status.busy": "2021-03-29T11:50:49.322961Z",
     "iopub.status.idle": "2021-03-29T11:50:49.326483Z",
     "shell.execute_reply": "2021-03-29T11:50:49.327032Z"
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Creating PT data samplers and loaders:\n",
    "train_sampler = SubsetRandomSampler(train_indices)\n",
    "valid_sampler = SubsetRandomSampler(val_indices)\n",
    "BATCH_SIZE = 16\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(train_data, batch_size=BATCH_SIZE,\n",
    "                                             sampler=train_sampler)\n",
    "valid_loader = torch.utils.data.DataLoader(train_data, batch_size=BATCH_SIZE,\n",
    "                                             sampler=valid_sampler)\n",
    "test_loader = torch.utils.data.DataLoader(test_data, batch_size=BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "cf3bb9bf",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-03-29T11:50:49.356639Z",
     "iopub.status.busy": "2021-03-29T11:50:49.355943Z",
     "iopub.status.idle": "2021-03-29T11:50:49.359522Z",
     "shell.execute_reply": "2021-03-29T11:50:49.360085Z"
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='mps')"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Device configuration\n",
    "device = torch.device('mps' if torch.backends.mps.is_available() else 'cpu')\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "d938e03b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded pretrained weights for efficientnet-b4\n"
     ]
    }
   ],
   "source": [
    "def make_model():\n",
    "    model = EfficientNet.from_pretrained('efficientnet-b4') \n",
    "    model._fc = nn.Linear(in_features=1792, out_features=5, bias=True)\n",
    "    return model\n",
    "\n",
    "model = make_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "c92dfe6d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-03-29T11:50:49.396116Z",
     "iopub.status.busy": "2021-03-29T11:50:49.395422Z",
     "iopub.status.idle": "2021-03-29T11:50:49.428700Z",
     "shell.execute_reply": "2021-03-29T11:50:49.428001Z"
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Define Models \n",
    "\n",
    "class Classifier(nn.Module):\n",
    "    def __init__(self, num_classes):\n",
    "        super(Classifier, self).__init__()\n",
    "        # Block 1\n",
    "        self.conv1 = nn.Conv2d(in_channels = 3, out_channels = 32, kernel_size = 3, stride = 2, padding = 1)\n",
    "        self.relu1 = nn.ReLU()\n",
    "        self.maxpool1 = nn.MaxPool2d(kernel_size = 2)\n",
    "\n",
    "        #Block 2\n",
    "        self.conv2 = nn.Conv2d(in_channels = 32, out_channels = 64, kernel_size = 3, stride = 2)\n",
    "        self.relu2 = nn.ReLU()\n",
    "        self.maxpool2 = nn.MaxPool2d(kernel_size=2)\n",
    "\n",
    "        #Block 3\n",
    "        self.conv3 = nn.Conv2d(in_channels = 64, out_channels = 32, kernel_size = 3, stride = 2)\n",
    "        self.relu3 = nn.ReLU()\n",
    "        self.maxpool3 = nn.MaxPool2d(kernel_size=2)\n",
    "\n",
    "        # last fully-connected layer\n",
    "        self.fc = nn.Linear(32*3*3, num_classes)\n",
    "\n",
    "\n",
    "    def forward(self, input):\n",
    "\n",
    "        x = self.maxpool1(self.relu1(self.conv1(input)))\n",
    "        x = self.maxpool2(self.relu2(self.conv2(x)))\n",
    "        x = self.maxpool3(self.relu3(self.conv3(x)))\n",
    "\n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = self.fc(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "# model = Classifier(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "b362a09f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-03-29T11:50:49.458735Z",
     "iopub.status.busy": "2021-03-29T11:50:49.457972Z",
     "iopub.status.idle": "2021-03-29T11:50:49.461960Z",
     "shell.execute_reply": "2021-03-29T11:50:49.461357Z"
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "criterion = torch.nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-4)\n",
    "scheduler = torch.optim.lr_scheduler.OneCycleLR(\n",
    "                                    optimizer,\n",
    "                                    max_lr=0.001,\n",
    "                                    epochs=30,\n",
    "                                    steps_per_epoch=int(len(train_data) / BATCH_SIZE), \n",
    "                                    pct_start=0.1,\n",
    "                                    anneal_strategy='cos',\n",
    "                                    final_div_factor=10**5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "f21abcb4",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-03-29T11:50:49.496069Z",
     "iopub.status.busy": "2021-03-29T11:50:49.495310Z",
     "iopub.status.idle": "2021-03-29T11:50:49.499172Z",
     "shell.execute_reply": "2021-03-29T11:50:49.498453Z"
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def train(model, criterion, data_loader, optimizer, scheduler, num_epochs):\n",
    "    \"\"\"Simple training loop for a PyTorch model.\"\"\" \n",
    "    \n",
    "    # Make sure model is in training mode.\n",
    "    model.train()\n",
    "    \n",
    "    # Move model to the device (CPU or MPS or GPU).\n",
    "    model.to(device)\n",
    "    \n",
    "    # Exponential moving average of the loss.\n",
    "    ema_loss = None\n",
    "\n",
    "    print('----- Training Loop -----')\n",
    "    # Loop over epochs.\n",
    "    for epoch in trange(num_epochs):\n",
    "        \n",
    "      # Loop over data.\n",
    "      for batch_idx, (features, target) in enumerate(data_loader):\n",
    "            \n",
    "          # Forward pass.\n",
    "        output = model(features.to(device))\n",
    "        loss = criterion(output.to(device), target.to(device))\n",
    "\n",
    "          # Backward pass.\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        scheduler.step()\n",
    "\n",
    "      # NOTE: It is important to call .item() on the loss before summing.\n",
    "        if ema_loss is None:\n",
    "            ema_loss = loss.item()\n",
    "        else:\n",
    "            ema_loss += (loss.item() - ema_loss) * 0.01 \n",
    "\n",
    "      # Print out progress the end of epoch.\n",
    "      print('Epoch: {} \\tLoss: {:.6f}'.format(epoch, ema_loss),)\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "e5101053",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-03-29T11:50:49.532699Z",
     "iopub.status.busy": "2021-03-29T11:50:49.531985Z",
     "iopub.status.idle": "2021-03-29T11:50:49.536002Z",
     "shell.execute_reply": "2021-03-29T11:50:49.535353Z"
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def test(model, data_loader):\n",
    "    \"\"\"Measures the accuracy of a model on a data set.\"\"\" \n",
    "    # Make sure the model is in evaluation mode.\n",
    "    model.eval()\n",
    "    correct = 0\n",
    "    print('----- Model Evaluation -----')\n",
    "    # We do not need to maintain intermediate activations while testing.\n",
    "    with torch.no_grad():\n",
    "        \n",
    "        # Loop over test data.\n",
    "        for images, target in data_loader:\n",
    "            # Forward pass.\n",
    "            output = model(images.to(device))\n",
    "            \n",
    "            # Get the label corresponding to the highest predicted probability.\n",
    "            pred = output.argmax(dim=1, keepdim=True)\n",
    "            # Count number of correct predictions.\n",
    "            correct += pred.cpu().eq(target.view_as(pred)).sum().item()\n",
    "\n",
    "    # Print test accuracy.\n",
    "    percent = 100. * correct / len(data_loader.dataset)\n",
    "    print(f'Validation accuracy: {correct} / {len(data_loader.dataset)} ({percent:.0f}%)')\n",
    "    torch.save(model.state_dict(), 'model.ckpt')\n",
    "    return percent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "d032bf01",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-03-29T11:50:49.567361Z",
     "iopub.status.busy": "2021-03-29T11:50:49.566686Z",
     "iopub.status.idle": "2021-03-29T12:00:25.476410Z",
     "shell.execute_reply": "2021-03-29T12:00:25.475689Z"
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----- Training Loop -----\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|██        | 1/5 [02:01<08:05, 121.38s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0 \tLoss: 0.937459\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|████      | 2/5 [03:59<05:57, 119.22s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1 \tLoss: 0.622544\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|██████    | 3/5 [05:57<03:57, 118.75s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 2 \tLoss: 0.590200\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|████████  | 4/5 [07:55<01:58, 118.42s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 3 \tLoss: 0.568897\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5/5 [09:52<00:00, 118.58s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 4 \tLoss: 0.495079\n",
      "----- Model Evaluation -----\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test accuracy: 894 / 5656 (16%)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "15.806223479490805"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_epochs = 5\n",
    "train(model, criterion, train_loader, optimizer, scheduler, num_epochs=num_epochs)\n",
    "test(model, valid_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(model, data_loader):\n",
    "    model.eval()\n",
    "    preds = []\n",
    "    for images, _ in data_loader:\n",
    "        # Forward pass.\n",
    "        output = model(images.to(device))\n",
    "        # Get the label corresponding to the highest predicted probability.\n",
    "        pred = output.argmax(dim=1, keepdim=True)\n",
    "        for p in pred:\n",
    "            pred_class = train_data.classes_dict[p.item()]\n",
    "            preds.append(pred_class)\n",
    "    return preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "e39642ef",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-03-29T12:00:25.513240Z",
     "iopub.status.busy": "2021-03-29T12:00:25.512426Z",
     "iopub.status.idle": "2021-03-29T12:00:25.515568Z",
     "shell.execute_reply": "2021-03-29T12:00:25.516089Z"
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def generate_submission_file(predictions):\n",
    "    mapped_preds = []\n",
    "    for idx in range(len(test_data)):\n",
    "        mapped_preds.append({'Category': predictions[idx], 'Id': test_data.get_image_filename(idx)})\n",
    "    pd.DataFrame(mapped_preds).to_csv(\"sample_submission_file.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = predict(model, test_loader)\n",
    "# Make submission here\n",
    "generate_submission_file(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "none",
   "dataSources": [
    {
     "databundleVersionId": 8400328,
     "sourceId": 77142,
     "sourceType": "competition"
    }
   ],
   "isGpuEnabled": false,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 13.207064,
   "end_time": "2024-04-30T12:35:18.672226",
   "environment_variables": {},
   "exception": true,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2024-04-30T12:35:05.465162",
   "version": "2.2.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
